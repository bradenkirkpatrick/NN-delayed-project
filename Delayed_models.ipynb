{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get data\n",
    "data = pd.read_csv(\"combined_air_travel_data.parquet\")\n",
    "train_set, test_set = train_test_split(data, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra code\n",
    "from sklearn.metrics import make_scorer, precision_score, recall_score, precision_recall_curve\n",
    "def precision_at_recall(y, y_pred, *, recall, **kwargs):\n",
    "    \"\"\"\n",
    "    Calculate the precision at a given recall level.\n",
    "\n",
    "    To use this with cross_val_score, you need to use the make_scorer function to\n",
    "    create a scoring function that can be used with cross_val_score. For example:\n",
    "\n",
    "        scorer = make_scorer(precision_at_recall, recall=0.9)  # 0.9 is the minimum recall level\n",
    "        cross_val_score(model, X, y, cv=5, scoring=scorer)\n",
    "\n",
    "    The default will only work for binary classification problems. You must change the\n",
    "    average parameter if you want to use for multiclass classification. For example:\n",
    "\n",
    "        scorer = make_scorer(precision_at_recall, recall=0.9, average=\"micro\")\n",
    "    \"\"\"\n",
    "    return precision_score(y, y_pred, **kwargs) if recall_score(y, y_pred, **kwargs) > recall else 0.0\n",
    "\n",
    "def recall_at_precision(y, y_pred, *, precision, **kwargs):\n",
    "    \"\"\"\n",
    "    Calculate the recall at a given precision level.\n",
    "\n",
    "    To use this with cross_val_score, you need to use the make_scorer function to\n",
    "    create a scoring function that can be used with cross_val_score. For example:\n",
    "\n",
    "        scorer = make_scorer(recall_at_precision, precision=0.9)\n",
    "        cross_val_score(model, X, y, cv=5, scoring=scorer)\n",
    "\n",
    "    The default will only work for binary classification problems. You must change the\n",
    "    average parameter if you want to use for multiclass classification. For example:\n",
    "\n",
    "        scorer = make_scorer(recall_at_precision, precision=0.9, average=\"micro\")\n",
    "    \"\"\"\n",
    "    return recall_score(y, y_pred, **kwargs) if precision_score(y, y_pred, **kwargs) > precision else 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifiers to Try for Project\n",
    "==============================\n",
    "List of classifiers to try along with their most critical hyperparameters. You should expect your short listing of models to take on the order of a day and your hyperparameter tuning multiple days.\n",
    "\n",
    "Note: you may want to look into each one briefly just to get some info like if they are appropriate for our dataset (considering the number of samples vs features). You will want to read the documentation for default values and understanding what ranges may be useful to examine.\n",
    "\n",
    " \n",
    "\n",
    "Linear Classifiers\n",
    "------------------\n",
    "\n",
    "All of these have a coef_ parameter which can be useful during exploration, especially if the penalty is 'l1' which makes the coefficient of unimportant features (near) 0 (but the models all require properly scaled data for the coefficients to be meaningful).\n",
    "\n",
    "LogisticRegression\n",
    "penalty: l2 (default), l1 (for sparse models), elasticnet, or none\n",
    "C: 1 (default), decrease for regularization\n",
    "dual: False (default)\n",
    "solver: different solvers are better for different problems\n",
    "SGDClassifier [basically an online version of LogisticRegression, if online is not needed then you probably don't need this]\n",
    "loss: hinge (default, like LinearSVC) or log (like LogisticRegression)\n",
    "penalty: l2 (default), l1, elasticnet, or none\n",
    "alpha: default 0.0001, increase for regularization\n",
    "l1_ratio: ratio of Lasso vs Ridge if penalty='elasticnet'\n",
    "max_iter/tol: max number of steps to attempt and target tolerance to achieve\n",
    "learning_rate: constant, optimal, invscaling (default), adaptive\n",
    "eta0: initial learning rate, default is 0.01\n",
    "shuffle: default True, shuffle data between iterations\n",
    "early_stopping/validation_fraction/n_iter_no_change: early stopping regularization\n",
    " \n",
    "\n",
    "Neural Network Classifiers\n",
    "--------------------------\n",
    "\n",
    "MLPClassifier (i.e. neural network)\n",
    "hidden_layer_sizes: default is (100,)\n",
    "activation: 'relu' (default), 'identity', 'logistic', 'tanh'\n",
    "alpha: default 0.0001, increase for regularization (always L2)\n",
    "max_iter/tol: max number of steps to attempt and target tolerance to achieve\n",
    "learning_rate_init: initial learning rate, default is 0.001\n",
    "batch_size: sizes of batches\n",
    "shuffle: default True, shuffle data between iterations\n",
    "early_stopping/validation_fraction/n_iter_no_change: early stopping regularization\n",
    " \n",
    "\n",
    "Tree-Based Classifiers\n",
    "----------------------\n",
    "\n",
    "All of these have a feature_importances_ parameter which can be useful during exploration. Scaling does not need to be done for that parameter to have meaning.\n",
    "\n",
    "DecisionTreeClassifier\n",
    "criterion: gini (default) or entropy\n",
    "splitter: best (default) or random (faster)\n",
    "max_depth, , max_leaf_nodes, min_samples_split, min_samples_leaf, min_impurity_split, etc: control tree generation, decrease max_* to regularize, increase min_* to regularize\n",
    "presort: setting to True can increase speed for small datasets or restricted depths\n",
    "RandomForestClassifier and ExtraTreesClassifier\n",
    "n_estimators: default 100\n",
    "Supports all hyperparameters of DecisionTreeClassifier listed above except splitter (always best) and presort (always False)\n",
    "max_features defaults to sqrt, also supports log2, int (for a count), or float (for a percentage)\n",
    "max_samples & bootstrap: default all samples with bootstrapping\n",
    "GradientBoostingClassifier\n",
    "or XGBClassifierLinks to an external site. - improved version but requires an external library to be installed and has a bit difference hyperparameters\n",
    "learning_rate: default 0.1, lower to increase regularization, higher to go faster\n",
    "n_estimators: default 100, balance with learning rate, can be fairly high though\n",
    "subsample: default is 1.0, values <1.0 enable stochastic gradient boosting\n",
    "n_iter_no_change/validation_fraction: early stopping regularization\n",
    "Supports most max_* and min_* hyperparameters of DecisionTreeClassifier listed above\n",
    "max_features defaults to sqrt, also supports log2, int (for a count), or float (for a percentage)\n",
    " \n",
    "\n",
    "Instance-Based Classifiers\n",
    "--------------------------\n",
    "\n",
    "KNeighborsClassifier\n",
    "n_neighbors: 5 (default)\n",
    "weights: 'uniform' (default) or 'distance'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
